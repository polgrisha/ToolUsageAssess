{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key_path = '../OPENAI_KEY'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4toolsdata = json.load(open('../data/gpt4tools_71k.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loadeed 55 generated tools\n"
     ]
    }
   ],
   "source": [
    "# gen_tools_path = Path('../data/gpt3_generations_tools/gen_tools.jsonl')\n",
    "gen_tools_path = Path('../data/gpt3_generations_tools_taskmatrix/gen_tools.jsonl')\n",
    "\n",
    "gen_tools = [json.loads(l) for l in gen_tools_path.open()]\n",
    "print(f\"Loadeed {len(gen_tools)} generated tools\")\n",
    "\n",
    "\n",
    "gen_examples_path = Path('../data/gpt3_generations_tools_taskmatrix/gen_examples.jsonl')\n",
    "gen_examples = []\n",
    "if gen_examples_path.exists():\n",
    "    gen_examples.extend([json.loads(l) for l in gen_examples_path.open()])\n",
    "    print(f\"loaded {len(gen_examples)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gpt3_request(prompt: str):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant, useful for data generation.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "        stop=None,\n",
    "        )\n",
    "    return response\n",
    "\n",
    "def extract(response: openai.openai_object.OpenAIObject):\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "def sample_tools(tools: list, n=1):\n",
    "    return random.sample(tools, min(len(tools), n))\n",
    "\n",
    "def encode_prompt(tools: list):\n",
    "    \"\"\"Encode multiple tools into a single string.\"\"\"\n",
    "    prompt = f\"Please generate instruction for each of the given tools.\\n\"\n",
    "    prompt += \"Each tool is defined as \\\"<Tool Name>: <usage scenario>\\\"\\n\"\n",
    "    for idx, tool in enumerate(tools):\n",
    "        prompt += f\"{idx+1}. {tool['name']}: {tool['description']}\\n\"\n",
    "\n",
    "    prompt += \"Each example should follow the format \\\"<instruction>, [<tool name>, <input arguments>]\\\".\\n\\n\"\n",
    "\n",
    "    example_str = 'Here is an example for the tool \"Video Splitter\" -- \"Divide the video located at /path/to/video.mp4 into 10-second intervals.\", [Video Splitter, \"/path/to/video.mp4\", \"10 seconds\"]\"\\n'\n",
    "    prompt += example_str\n",
    "    prompt += \"Try not repeating the words from tool description, where possible. Provide diverse instructions.\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_batch = sample_tools(gen_tools, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please generate instruction for each of the given tools.\n",
      "Each tool is defined as \"<Tool Name>: <usage scenario>\"\n",
      "1. Speech Recognition: useful when you want to recognize speech from a microphone or audio file. The input to this tool should be an audio file path or a microphone input.\n",
      "2. Object Tracking in Image: useful when you want to track the position of an object in an image across multiple frames. The input to this tool should be a string, representing the path of the image file sequence.\n",
      "3. Audio Speed Changer: useful when you want to change the speed of an audio file. The input to this tool should be a string, representing the path of the audio file, and another string, representing the new speed.\n",
      "4. Video Editing: useful when you want to edit a video by trimming, cropping, adding music, or enhancing the video quality. The input to this tool should be a string, representing the path of the video file.\n",
      "5. Background Removal: useful when you want to remove the background from an image and create a transparent background. The input to this tool should be a string, representing the path of the image file.\n",
      "6. Speech Synthesis: useful when you want to generate an audio recording from text. The input to this tool should be a string, representing the text to be converted into speech.\n",
      "7. Image Resize: useful when you want to resize an image to a specific size or ratio. The input to this tool should be a string, representing the image_path and another string representing the desired size or aspect ratio.\n",
      "8. Video Splitter: useful when you want to split a video into different parts. The input to this tool should be a string, representing the video_path and another string representing the split duration or time interval.\n",
      "Each example should follow the format \"<instruction>, [<tool name>, <input arguments>]\".\n",
      "\n",
      "Here is an example for the tool \"Video Splitter\" -- \"Divide the video located at /path/to/video.mp4 into 10-second intervals.\", [Video Splitter, \"/path/to/video.mp4\", \"10 seconds\"]\"\n",
      "Try not repeating the words from tool description, where possible. Provide diverse instructions.\n"
     ]
    }
   ],
   "source": [
    "prompt = encode_prompt(tool_batch)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = make_gpt3_request(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Convert speech from an audio file located at /path/to/audio.wav, [Speech Recognition, \"/path/to/audio.wav\"].\n",
      "2. Track the position of a car in a sequence of images located at /path/to/image_sequence, [Object Tracking in Image, \"/path/to/image_sequence\"].\n",
      "3. Speed up an audio file located at /path/to/audio.mp3 by 50%, [Audio Speed Changer, \"/path/to/audio.mp3\", \"50% faster\"].\n",
      "4. Enhance the quality of the video located at /path/to/video.mov, [Video Editing, \"/path/to/video.mov\"].\n",
      "5. Remove the background from an image located at /path/to/image.png and create a transparent background, [Background Removal, \"/path/to/image.png\"].\n",
      "6. Generate an audio recording of the text \"Hello, how are you?\", [Speech Synthesis, \"Hello, how are you?\"].\n",
      "7. Resize an image located at /path/to/image.jpg to a width of 800 pixels, [Image Resize, \"/path/to/image.jpg\", \"800px width\"].\n",
      "8. Split a video located at /path/to/video.mp4 into three parts of equal length, [Video Splitter, \"/path/to/video.mp4\", \"3 parts of equal duration\"].\n"
     ]
    }
   ],
   "source": [
    "print(extract(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_response(response):\n",
    "    text = extract(response)\n",
    "    new_examples = []\n",
    "    for line in text.split('\\n'):\n",
    "        line = re.sub('^\\d+.', '', line).strip()\n",
    "        query, name_args = line.split(',', maxsplit=1)\n",
    "        name_args = name_args.strip()\n",
    "        name_args = name_args.removeprefix('[').removesuffix('].').removesuffix(']')\n",
    "        tool_name, input_args = name_args.split(',', maxsplit=1)\n",
    "        input_args = input_args.strip()\n",
    "        new_examples.append({\n",
    "            'name': tool_name,\n",
    "            'query': query,\n",
    "            'input_args': input_args\n",
    "        })\n",
    "    return new_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_examples_batch = postprocess_response(r)\n",
    "pprint(new_examples_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "batch_size = 8\n",
    "num_requests = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing 0 request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:26<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:26<00:00, 26.16s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "\n",
    "    random.shuffle(gen_tools)\n",
    "\n",
    "    for tool_batch in tqdm(batch(gen_tools, batch_size), total=len(gen_tools) // batch_size):\n",
    "\n",
    "        prompt = encode_prompt(tool_batch)\n",
    "        print(f\"doing {num_requests} request\")\n",
    "        response = make_gpt3_request(prompt)\n",
    "        num_requests += 1\n",
    "        new_examples_batch = postprocess_response(response)\n",
    "        gen_examples.extend(new_examples_batch)\n",
    "\n",
    "        with open(gen_examples_path, 'a') as fout:\n",
    "            for ex in gen_examples:\n",
    "                fout.write(json.dumps(ex) + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Object Tracking in Image',\n",
       "  'query': 'Track the movement of a car in the image sequence located at /path/to/car/images across different frames.',\n",
       "  'input_args': '\"/path/to/car/images\"]'},\n",
       " {'name': 'Image Resize',\n",
       "  'query': 'Resize the image located at /path/to/image.jpg to a size of 800x600.',\n",
       "  'input_args': '\"/path/to/image.jpg\", \"800x600\"]'},\n",
       " {'name': 'Text Summarization',\n",
       "  'query': 'Summarize the long report found at /path/to/report.docx into a brief summary.',\n",
       "  'input_args': '\"/path/to/report.docx\"]'},\n",
       " {'name': 'Video Splitter',\n",
       "  'query': 'Split the video located at /path/to/video.mp4 into different 1-minute parts.',\n",
       "  'input_args': '\"/path/to/video.mp4\", \"1 minute\"]'},\n",
       " {'name': 'Style Transfer',\n",
       "  'query': \"Transfer the style of Van Gogh's painting to a picture of a sunflower located at /path/to/sunflower.jpg.\",\n",
       "  'input_args': '\"/path/to/sunflower.jpg\", \"/path/to/van-gogh.jpg\"]'},\n",
       " {'name': 'Face Detection and Recognition',\n",
       "  'query': 'Detect and recognize faces in the picture located at /path/to/group-photo.jpg.',\n",
       "  'input_args': '\"/path/to/group-photo.jpg\"]'},\n",
       " {'name': 'Speech-to-Text Converter',\n",
       "  'query': 'Convert the audio file located at /path/to/audio.mp3 into a written transcript.',\n",
       "  'input_args': '\"/path/to/audio.mp3\"]'},\n",
       " {'name': 'Background Removal',\n",
       "  'query': 'Remove the background from the picture located at /path/to/image.png and get a transparent background.',\n",
       "  'input_args': '\"/path/to/image.png\"]'},\n",
       " {'name': 'Sentiment Analysis',\n",
       "  'query': 'Analyze the sentiment of a review about a product',\n",
       "  'input_args': '\"This product is great! I would definitely recommend it.\"]'},\n",
       " {'name': 'Image Filters',\n",
       "  'query': 'Apply a sepia filter to the image located at /path/to/image.jpeg',\n",
       "  'input_args': '\"/path/to/image.jpeg\", \"sepia\"]'},\n",
       " {'name': 'Image Super-Resolution',\n",
       "  'query': 'Increase the resolution of a low-quality image located at /path/to/low_res_image.jpeg',\n",
       "  'input_args': '\"/path/to/low_res_image.jpeg\"]'},\n",
       " {'name': 'Audio Transcriber',\n",
       "  'query': 'Transcribe a podcast episode from audio file located at /path/to/audio_file.mp3',\n",
       "  'input_args': '\"/path/to/audio_file.mp3\"]'},\n",
       " {'name': 'Object Tracking in Image',\n",
       "  'query': 'Track the motion of a person across multiple frames in a video sequence located at /path/to/video_sequence/',\n",
       "  'input_args': '\"/path/to/video_sequence/\"]'},\n",
       " {'name': 'Image Segmentation',\n",
       "  'query': 'Segment an image located at /path/to/image.jpeg using the watershed algorithm',\n",
       "  'input_args': '\"/path/to/image.jpeg\", \"watershed\"]'},\n",
       " {'name': 'Speech Recognition',\n",
       "  'query': 'Convert a voice recording at /path/to/voice_recording.wav into a written document',\n",
       "  'input_args': '\"/path/to/voice_recording.wav\"]'},\n",
       " {'name': 'Object Recognition',\n",
       "  'query': 'Identify any cats present in an image located at /path/to/image.jpeg',\n",
       "  'input_args': '\"/path/to/image.jpeg\", \"cat\"]'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
